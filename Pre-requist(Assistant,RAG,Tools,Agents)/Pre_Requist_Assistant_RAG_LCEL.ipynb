{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "GOOGLE_API_KEY=os.getenv(\"GOOGLE_API_KEY\")\n",
    "TAVILY_API_KEY=os.getenv(\"TAVILY_API_KEY\")\n",
    "GROQ_API_KEY=os.getenv(\"GROQ_API_KEY\")\n",
    "LANGCHAIN_API_KEY=os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "LANGCHAIN_PROJECT=os.getenv(\"LANGCHAIN_PROJECT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
    "os.environ[\"TAVILY_API_KEY\"] = TAVILY_API_KEY\n",
    "os.environ[\"GROQ_API_KEY\"]= GROQ_API_KEY\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = LANGCHAIN_API_KEY\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"]=LANGCHAIN_PROJECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sunny\\LangGraph-End-to-End-Course\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.0-pro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''from langchain_huggingface import HuggingFaceEmbeddings\n",
    "embeddings=HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")'''\n",
    "from langchain_groq import ChatGroq\n",
    "import os\n",
    "llm=ChatGroq(model_name=\"Gemma2-9b-It\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello there! How can I assist you today?\n",
      "goodbye take care yourself\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    question=input(\"type your question. if you want to quit the chat write quit\")\n",
    "    if question !=\"quit\":\n",
    "        print(llm.invoke(question).content)\n",
    "    else:\n",
    "        print(\"goodbye take care yourself\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.messages import AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = InMemoryChatMessageHistory()\n",
    "    return store[session_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "config = {\"configurable\": {\"session_id\": \"firstchat\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_with_memory=RunnableWithMessageHistory(llm,get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_with_memory.invoke((\"Hi! I'm sunnysavita\"),config=config).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_with_memory.invoke((\"tell me what is my name?\"),config=config).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain import PromptTemplate\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough , RunnableLambda\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "### Reading the txt files from source directory\n",
    "\n",
    "loader = DirectoryLoader('../data', glob=\"./*.txt\", loader_cls=TextLoader)\n",
    "docs = loader.load()\n",
    "\n",
    "### Creating Chunks using RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=50,\n",
    "    chunk_overlap=10,\n",
    "    length_function=len\n",
    ")\n",
    "new_docs = text_splitter.split_documents(documents=docs)\n",
    "doc_strings = [doc.page_content for doc in new_docs]\n",
    "\n",
    "###  BGE Embddings\n",
    "\n",
    "'''from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
    "\n",
    "model_name = \"BAAI/bge-base-en-v1.5\"\n",
    "model_kwargs = {'device': 'cpu'}\n",
    "encode_kwargs = {'normalize_embeddings': True} # set True to compute cosine similarity\n",
    "embeddings = HuggingFaceBgeEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs,\n",
    ")\n",
    "'''\n",
    "\n",
    "### Creating Retriever using Vector DB\n",
    "\n",
    "db = Chroma.from_documents(new_docs, embeddings)\n",
    "retriever = db.as_retriever(search_kwargs={\"k\": 4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = PromptTemplate.from_template(template)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "retrieval_chain = (\n",
    "    RunnableParallel({\"context\": retriever, \"question\": RunnablePassthrough()})\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- **Llama 3 is a large language model developed by Google.**\n",
      "- **It was released in April 2024.**\n",
      "- **It is used by a variety of services, including Google Search and Gmail.**\n"
     ]
    }
   ],
   "source": [
    "question =\"what is llama3? can you highlight 3 important points?\"\n",
    "print(retrieval_chain.invoke(question))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's Start with Tools and Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_wrapper = WikipediaAPIWrapper(top_k_results=5, doc_content_chars_max=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool = WikipediaQueryRun(api_wrapper=api_wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wikipedia'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': {'description': 'query to look up on wikipedia',\n",
       "  'title': 'Query',\n",
       "  'type': 'string'}}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool.args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool.return_direct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page: LangChain\n",
      "Summary: LangChain is a framework designed to simplify the creation of applications \n"
     ]
    }
   ],
   "source": [
    "print(tool.run({\"query\": \"langchain\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Page: LangChain\\nSummary: LangChain is a framework designed to simplify the creation of applications '"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool.run(\"langchain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sunny\\LangGraph-End-to-End-Course\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3577: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WikiInputs(BaseModel):\n",
    "    query: str = Field(description=\"query to look up in Wikipedia, should be 3 or less words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for WikipediaQueryRun\nargs_schema\n  Input should be a subclass of BaseModel [type=is_subclass_of, input_value=<class '__main__.WikiInputs'>, input_type=ModelMetaclass]\n    For further information visit https://errors.pydantic.dev/2.9/v/is_subclass_of",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m tool\u001b[38;5;241m=\u001b[39m\u001b[43mWikipediaQueryRun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwiki-tool\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlook up things in wikipedia\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs_schema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mWikiInputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mapi_wrapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapi_wrapper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_direct\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sunny\\LangGraph-End-to-End-Course\\venv\\lib\\site-packages\\langchain_core\\tools\\base.py:437\u001b[0m, in \u001b[0;36mBaseTool.__init__\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    432\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_basemodel_subclass(kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124margs_schema\u001b[39m\u001b[38;5;124m\"\u001b[39m]):\n\u001b[0;32m    433\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    434\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124margs_schema must be a subclass of pydantic BaseModel. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    435\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124margs_schema\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    436\u001b[0m         )\n\u001b[1;32m--> 437\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\sunny\\LangGraph-End-to-End-Course\\venv\\lib\\site-packages\\langchain_core\\load\\serializable.py:112\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    111\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\"\"\"\u001b[39;00m\n\u001b[1;32m--> 112\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\sunny\\LangGraph-End-to-End-Course\\venv\\lib\\site-packages\\pydantic\\main.py:212\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[1;34m(self, **data)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[0;32m    211\u001b[0m __tracebackhide__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 212\u001b[0m validated_self \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n\u001b[0;32m    214\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    215\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA custom validator is returning a value other than `self`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    216\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturning anything other than `self` from a top level model validator isn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt supported when validating via `__init__`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    217\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    218\u001b[0m         category\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    219\u001b[0m     )\n",
      "\u001b[1;31mValidationError\u001b[0m: 1 validation error for WikipediaQueryRun\nargs_schema\n  Input should be a subclass of BaseModel [type=is_subclass_of, input_value=<class '__main__.WikiInputs'>, input_type=ModelMetaclass]\n    For further information visit https://errors.pydantic.dev/2.9/v/is_subclass_of"
     ]
    }
   ],
   "source": [
    "tool=WikipediaQueryRun(\n",
    "    name=\"wiki-tool\",\n",
    "    description=\"look up things in wikipedia\",\n",
    "    args_schema=WikiInputs,\n",
    "    api_wrapper=api_wrapper,\n",
    "    return_direct=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wikipedia'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'look up things in wikipedia'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': {'title': 'Query',\n",
       "  'description': 'query to look up in Wikipedia, should be 3 or less words',\n",
       "  'type': 'string'}}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool.args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool.return_direct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page: LangChain\n",
      "Summary: LangChain is a framework designed to simplify the creation of applications \n"
     ]
    }
   ],
   "source": [
    "print(tool.run(\"langchain\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# youtube search tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import YouTubeSearchTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool=YouTubeSearchTool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'youtube_search'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'search for youtube videos associated with a person. the input to this tool should be a comma separated list, the first part contains a person name and the second a number that is the maximum number of video results to return aka num_results. the second part is optional'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['https://www.youtube.com/watch?v=Ik8gNjJ-13I&pp=ygUMc3Vubnkgc2F2aXRh', 'https://www.youtube.com/watch?v=ABK00e2XdPo&pp=ygUMc3Vubnkgc2F2aXRh']\""
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool.run(\"sunny savita\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool = TavilySearchResults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': 'https://www.npr.org/2023/09/03/1197497458/the-latest-on-the-burning-man-flooding',\n",
       "  'content': \"There are also reports that at least one person has died at the counterculture festival about a hundred miles north of Reno, Nev. Earlier this afternoon, I caught up with NPR's Claudia Peschiutta, who's at her first burn, and she told me it's muddy where she is, but that she and her camp family have been making the best of things.\\n National\\nThe latest on the Burning Man flooding\\nClaudia Peschiutta\\nAuthorities are investigating a death at the Burning Man festival in the Nevada desert after tens of thousands of people are stuck in camps because of rain.\\n SCOTT DETROW, HOST:\\nKnee-deep mud, warnings to conserve food and water, orders to shelter in place - this is all at Burning Man 2023 after torrential rains turned the Black Rock Desert into miles and miles of mud. I mean, mostly what I've seen from my personal experience is just any sort of need that you have, somebody, whether friend or neighbor or stranger, will jump in to help you out in some way. And I should mention that desert Wi-Fi is doing the best as it can as we talk to you, dropping in and out.\"},\n",
       " {'url': 'https://www.nbcnews.com/news/us-news/live-blog/live-updates-burning-man-flooding-keeps-thousands-stranded-nevada-site-rcna103193',\n",
       "  'content': \"Profile\\nSections\\ntv\\nFeatured\\nMore From NBC\\nFollow NBC News\\nnews Alerts\\nThere are no new alerts at this time\\nBurning Man flooding keeps thousands stranded at Nevada site as authorities investigate 1 death\\nBurning Man attendees struggling to get home\\n70,000+ stuck at Burning Man: When will they be able to get out?\\n Thousands still stranded at Burning Man after torrential rain\\nBurning Man revelers unfazed by deluge and deep mud\\nReuters\\nThousands of Burning Man attendees partied hard on Sunday despite downpours that turned the Nevada desert where the annual arts and music festival takes place into a sea of sticky mud and led officials to order the multitudes to shelter in place.\\n Neal Katyal warns hiking in the mud\\ncan be 'worse than walking on ice'\\nDoha Madani\\nNeal Katyal, the former acting U.S. solicitor general, is among the Burning Man attendees who decided to take the risk and hike out of the festival grounds.\\n Videos posted to his Instagram story show Diplo walking through mud before, he says, he hitchhiked to Gerlach and Reno to make a flight to Washington, D.C.\\n“I just got done DJ’ing for three hours, after walking f---ing for four hours out of the desert and taking a flight, mud still on my face,” he said in a video posted to his Instagram story last night.\\n Burning Man memes are swamping social media\\nAngela Yang\\nAs heavy rain turns Burning Man 2023 into a muddy mess, a deluge of unsympathetic jokes has swamped the internet outside Black Rock City, the temporary location built annually for the nine-day festival in the remote desert of Nevada.\\n\"},\n",
       " {'url': 'https://www.cnn.com/2023/09/05/us/burning-man-storms-shelter-exodus-tuesday/index.html',\n",
       "  'content': \"CNN values your feedback\\nBurning Man attendees make a mass exodus after a dramatic weekend that left thousands stuck in the Nevada desert\\nThousands of Burning Man attendees finally made their mass exodus after intense rain over the weekend flooded camp sites and filled them with thick, ankle-deep mud – stranding more than 70,000 free-spirited revelers as they waited for the Nevada desert city to dry out.\\n Burning Man organizers lift driving ban after heavy rains left the event smothered in mud and trapped thousands\\nThe area was still muddy and parts were still difficult to navigate, organizers warned, and the wait time to leave the city Monday night was about seven hours. Diplo hitchhiked ride out of rain-drenched Burning Man after walking miles 'through the mud' and actually made it to his DC concert\\n“Quite a wet start to September for much of eastern CA-western NV,” the National Weather Service in Reno wrote on X. ” “As soon as the tents started getting water-logged or unlivable, people in RVs started taking in some of the tenters, so everybody was warm,” Kaz Qamruddin, who attended the event, told CNN’s Brianna Keilar Monday.\\n From wood blocks to 'poop buckets,' how Burning Man organizers told festivalgoers to prepare for heavy rain\\nAmong the early departures was music DJ Diplo, who told CNN he walked several miles in the muddy desert Saturday morning along with other celebrities, including Chris Rock, Cindy Crawford, Kaia Gerber and Austin Butler.\"},\n",
       " {'url': 'https://abcnews.go.com/US/burning-man-flooding-happened-stranded-festivalgoers/story?id=102908331',\n",
       "  'content': '\"\\nTop Stories\\nMacy\\'s Thanksgiving Day Parade temporarily halted by pro-Palestinian protesters\\nGuns N\\' Roses singer Axl Rose accused of alleged 1989 sexual assault by former model\\nFBI: Rainbow Bridge crash, explosion not connected to terrorism\\nToxic chemical spill from Kentucky train derailment forces residents to flee homes\\nHezbollah fires rockets at north Israel after an airstrike kills 5 of the group\\'s senior fighters\\nABC News Live\\n24/7 coverage of breaking news and live events ABC News\\nVideo\\nLive\\nShows\\nElection 2024\\n538\\nStream on\\nBurning Man flooding: What happened to stranded festivalgoers?\\n In response to the unusual weather, event organizers shut down traffic in or out of what is called Black Rock City -- where the festival is held in the desert -- including the local airport.\\n MORE: These US regions will experience scorching temperatures for the remainder of Labor Day weekend\\nOn Sunday, mobile cell trailers to boost cell service and charging stations were placed around the festival grounds amid the recovery efforts, according to organizers.\\n This is typically the driest time of the year for the desert, and it does not take much rain to make the desert floor a mud bath.\\n'},\n",
       " {'url': 'https://www.today.com/news/what-is-burning-man-flood-death-rcna103231',\n",
       "  'content': '\"\\nAn update on BurningMan.org posted the night of Sept. 3 offered those still on site a \"Wet Playa Survival Guide\" with tips, as well as an update saying that conditions were \"improving\" and that roads in Black Rock City were expected to open on Sept. 4 for \"Exodus.\"\\n\"Thank goodness this community knows how to take care of each other,\" the Instagram page for Burning Man Information Radio wrote on a post predicting more rain.\\nNeal Katyal, Chris Rock and others detail their ‘escape’ from Black Rock City\\nComedian Chris Rock and Diplo, producer and DJ,\\xa0were among this year\\'s Burning Man attendees. Why are people stranded at Burning Man?\\nEach year participants in the Burning Man event gather for nine days in an \"annual experiment in temporary community dedicated to Radical Self-expression and Radical Self-reliance,\" according to burningman.org.\\nHeld in Nevada since 1991, the festival sees dreamers, artists, tech founders and celebrities — among others — converge to create a temporary community in the desert.\\n By Sept. 1, organizers tweeted on X that the more than 70,000 attendees of Burning Man should \"help each other stay safe\" and that the gate and airport in and out of the area was closed due to the impossibility for vehicles to \"traverse the playa. In 2014, a 29-year-old woman was hit by a bus outside of Black Rock City, and a motorcycle accident claimed the life of a friend of the Burning Man founders back in 1996, according to an article in the Reno Gazette Journal.\\n \"A fan offered Chris Rock and I a ride out of burning man in the back of a pick up,\" Diplo wrote in a text overlay of the video.\\n'}]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool.invoke({\"query\": \"What happened in the latest burning man floods\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor,create_openai_functions_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = \"\"\"You are an assistant.\"\"\"\n",
    "base_prompt = hub.pull(\"langchain-ai/openai-functions-template\")\n",
    "prompt = base_prompt.partial(instructions=instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "tavily_tool = TavilySearchResults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [tavily_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_openai_functions_agent(llm, tools, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor = AgentExecutor(\n",
    "    agent=agent,\n",
    "    tools=tools,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in StdOutCallbackHandler.on_chain_start callback: AttributeError(\"'NoneType' object has no attribute 'get'\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `tavily_search_results_json` with `{'query': 'who was the mahatma mahatma gandhi'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m[{'url': 'https://historycooperative.org/stay-story-mahatma-gandhi/', 'content': \"Mahatma Gandhi, also known as Mohandas Karamchand Gandhi, was a prominent figure in India's struggle for independence from British rule. His approach to non-violent protest and civil disobedience became a beacon for peaceful movements worldwide. Gandhi's beliefs in simplicity, non-violence, and truth had a profound impact on the world, influencing other leaders like Martin Luther\"}, {'url': 'https://www.britannica.com/summary/Mahatma-Gandhi', 'content': 'Mahatma Gandhi summary\\nExplore the life of Mahatma Gandhi as a political and social activist\\nMahatma Gandhi, byname of Mohandas Karamchand Gandhi,\\n(born Oct. 2, 1869, Porbandar, India—died Jan. 30, 1948, Delhi), Preeminent leader of Indian nationalism and prophet of nonviolence in the 20th century.\\n He refashioned the Indian National Congress into an effective political instrument of Indian nationalism and undertook major campaigns of nonviolent resistance in 1920–22, 1930–34 (including his momentous march to the sea to collect salt to protest a government monopoly), and 1940–42. His success in South Africa gave him an international reputation, and in 1915 he returned to India and within a few years became the leader of a nationwide struggle for Indian home rule. Gandhi grew up in a home steeped in religion, and he took for granted religious tolerance and the doctrine of ahimsa (noninjury to all living beings). India achieved dominion status in 1947, but the partition of the subcontinent into India and Pakistan was a great disappointment to Gandhi, who had long worked for Hindu-Muslim unity.'}, {'url': 'https://www.biographyonline.net/politicians/indian/gandhi.html', 'content': \"Mahatma Gandhi was a prominent Indian political leader who was a leading figure in the campaign for Indian independence. He employed non-violent principles and peaceful disobedience as a means to achieve his goal. He was assassinated in 1948, shortly after achieving his life goal of Indian independence. In India, he is known as 'Father of the ...\"}, {'url': 'https://www.britannica.com/summary/Mahatma-Gandhis-Achievements', 'content': \"Mahatma Gandhi Mahatma Gandhi in 1931. James A. Mills—AP/Shutterstock.com. Mahatma Gandhi was one of the greatest national and civil rights leaders of the 20th century. He served as a lawyer, politician, and activist in the struggle for social justice and for India's independence from British rule. Gandhi is internationally esteemed for his ...\"}, {'url': 'https://www.britannica.com/biography/Mahatma-Gandhi', 'content': 'Mohandas disregarded the last obstacle—the decree of the leaders of the Modh Bania subcaste (Vaishya caste), to which the Gandhis belonged, who forbade his trip to England as a violation of the Hindu religion—and sailed in September 1888. Gandhi’s father was a local government official working under the suzerainty of the British Raj, and his mother was a religious devotee who—like the rest of the family—practiced in the Vaishnavist tradition of Hinduism. Leo Tolstoy’s analysis of Christian theology, for example, came to bear heavily on Gandhi’s conception of spirituality, as did texts such as the Bible and the Quʾrān, and he first read the Bhagavadgita—a Hindu epic—in its English translation while living in Britain.\\n His father—Karamchand Gandhi, who was the dewan (chief minister) of Porbandar, the capital of a small principality in western India (in what is now Gujarat state) under British suzerainty—did not have much in the way of a formal education. But, besides the Vaishnava prejudice against vivisection, it was clear that, if he was to keep up the family tradition of holding high office in one of the states in Gujarat, he would have to qualify as a barrister.'}]\u001b[0m\u001b[32;1m\u001b[1;3mMahatma Gandhi, also known as Mohandas Karamchand Gandhi, was a prominent figure in India's struggle for independence from British rule. His approach to non-violent protest and civil disobedience became a beacon for peaceful movements worldwide. Gandhi's beliefs in simplicity, non-violence, and truth had a profound impact on the world, influencing other leaders like Martin Luther King Jr. \n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': 'who was the mahatma gandhi', 'output': \"Mahatma Gandhi, also known as Mohandas Karamchand Gandhi, was a prominent figure in India's struggle for independence from British rule. His approach to non-violent protest and civil disobedience became a beacon for peaceful movements worldwide. Gandhi's beliefs in simplicity, non-violence, and truth had a profound impact on the world, influencing other leaders like Martin Luther King Jr. \\n\"}\n"
     ]
    }
   ],
   "source": [
    "print(agent_executor.invoke({\"input\": \"who was the mahatma gandhi\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Showcase that one more agent also"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create our custom agent and custom tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import things that are needed generically\n",
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "from langchain.tools import BaseTool, StructuredTool, tool\n",
    "from pydantic import BaseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def search(query: str) -> str:\n",
    "    \"\"\"Look up things online.\"\"\"\n",
    "    return \"LangChain\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search\n",
      "Look up things online.\n",
      "{'query': {'title': 'Query', 'type': 'string'}}\n"
     ]
    }
   ],
   "source": [
    "print(search.name)\n",
    "print(search.description)\n",
    "print(search.args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two numbers.\"\"\"\n",
    "    return a * b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multiply\n",
      "Multiply two numbers.\n",
      "{'a': {'title': 'A', 'type': 'integer'}, 'b': {'title': 'B', 'type': 'integer'}}\n"
     ]
    }
   ],
   "source": [
    "print(multiply.name)\n",
    "print(multiply.description)\n",
    "print(multiply.args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SearchInput(BaseModel):\n",
    "    query: str = Field(description=\"should be a search query\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@tool(\"search-tool\", args_schema=SearchInput, return_direct=True)\n",
    "def search(query: str) -> str:\n",
    "    \"\"\"Look up things online.\"\"\"\n",
    "    return \"LangChain\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search-tool\n",
      "Look up things online.\n",
      "{'query': {'title': 'Query', 'type': 'string'}}\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sunny\\LangGraph-End-to-End-Course\\venv\\lib\\site-packages\\pydantic\\json_schema.py:2191: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='should be a search query' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
      "  warnings.warn(message, PydanticJsonSchemaWarning)\n"
     ]
    }
   ],
   "source": [
    "print(search.name)\n",
    "print(search.description)\n",
    "print(search.args)\n",
    "print(search.return_direct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Type\n",
    "\n",
    "from langchain.callbacks.manager import (\n",
    "    AsyncCallbackManagerForToolRun,\n",
    "    CallbackManagerForToolRun,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SearchInput(BaseModel):\n",
    "    query: str = Field(description=\"should be a search query\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CalculatorInput(BaseModel):\n",
    "    a: int = Field(description=\"first number\")\n",
    "    b: int = Field(description=\"second number\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# here is my custom tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import tool\n",
    "@tool\n",
    "def get_word_length(word: str) -> int:\n",
    "    \"\"\"Returns the length of a word.\"\"\"\n",
    "    return len(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_word_length.invoke(\"abc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [get_word_length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are very powerful assistant, but don't know current events\",\n",
    "        ),\n",
    "        (\"user\", \"{input}\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.format_scratchpad.openai_tools import (\n",
    "    format_to_openai_tool_messages,\n",
    ")\n",
    "from langchain.agents.output_parsers.openai_tools import OpenAIToolsAgentOutputParser\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = (\n",
    "    {\n",
    "        \"input\": lambda x: x[\"input\"],\n",
    "        \"agent_scratchpad\": lambda x: format_to_openai_tool_messages(\n",
    "            x[\"intermediate_steps\"]\n",
    "        ),\n",
    "    }\n",
    "    | prompt\n",
    "    | llm_with_tools\n",
    "    | OpenAIToolsAgentOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `get_word_length` with `{'word': 'eudca'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m5\u001b[0m\u001b[32;1m\u001b[1;3m5\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'actions': [ToolAgentAction(tool='get_word_length', tool_input={'word': 'eudca'}, log=\"\\nInvoking: `get_word_length` with `{'word': 'eudca'}`\\n\\n\\n\", message_log=[AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_4188', 'function': {'arguments': '{\"word\":\"eudca\"}', 'name': 'get_word_length'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls'}, id='run-6cc153ac-50f7-468e-871a-bb81fd15b1f7', tool_calls=[{'name': 'get_word_length', 'args': {'word': 'eudca'}, 'id': 'call_4188', 'type': 'tool_call'}], usage_metadata={'input_tokens': 966, 'output_tokens': 86, 'total_tokens': 1052}, tool_call_chunks=[{'name': 'get_word_length', 'args': '{\"word\":\"eudca\"}', 'id': 'call_4188', 'index': 0, 'type': 'tool_call_chunk'}])], tool_call_id='call_4188')],\n",
       "  'messages': [AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_4188', 'function': {'arguments': '{\"word\":\"eudca\"}', 'name': 'get_word_length'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls'}, id='run-6cc153ac-50f7-468e-871a-bb81fd15b1f7', tool_calls=[{'name': 'get_word_length', 'args': {'word': 'eudca'}, 'id': 'call_4188', 'type': 'tool_call'}], usage_metadata={'input_tokens': 966, 'output_tokens': 86, 'total_tokens': 1052}, tool_call_chunks=[{'name': 'get_word_length', 'args': '{\"word\":\"eudca\"}', 'id': 'call_4188', 'index': 0, 'type': 'tool_call_chunk'}])]},\n",
       " {'steps': [AgentStep(action=ToolAgentAction(tool='get_word_length', tool_input={'word': 'eudca'}, log=\"\\nInvoking: `get_word_length` with `{'word': 'eudca'}`\\n\\n\\n\", message_log=[AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_4188', 'function': {'arguments': '{\"word\":\"eudca\"}', 'name': 'get_word_length'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls'}, id='run-6cc153ac-50f7-468e-871a-bb81fd15b1f7', tool_calls=[{'name': 'get_word_length', 'args': {'word': 'eudca'}, 'id': 'call_4188', 'type': 'tool_call'}], usage_metadata={'input_tokens': 966, 'output_tokens': 86, 'total_tokens': 1052}, tool_call_chunks=[{'name': 'get_word_length', 'args': '{\"word\":\"eudca\"}', 'id': 'call_4188', 'index': 0, 'type': 'tool_call_chunk'}])], tool_call_id='call_4188'), observation=5)],\n",
       "  'messages': [FunctionMessage(content='5', additional_kwargs={}, response_metadata={}, name='get_word_length')]},\n",
       " {'output': '5',\n",
       "  'messages': [AIMessage(content='5', additional_kwargs={}, response_metadata={})]}]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(agent_executor.stream({\"input\": \"How many letters in the word eudca\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[{'actions': [ToolAgentAction(tool='get_word_length', tool_input={'word': 'eudca'}, log=\"\\nInvoking: `get_word_length` with `{'word': 'eudca'}`\\n\\n\\n\", message_log=[AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_4188', 'function': {'arguments': '{\"word\":\"eudca\"}', 'name': 'get_word_length'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls'}, id='run-6cc153ac-50f7-468e-871a-bb81fd15b1f7', tool_calls=[{'name': 'get_word_length', 'args': {'word': 'eudca'}, 'id': 'call_4188', 'type': 'tool_call'}], usage_metadata={'input_tokens': 966, 'output_tokens': 86, 'total_tokens': 1052}, tool_call_chunks=[{'name': 'get_word_length', 'args': '{\"word\":\"eudca\"}', 'id': 'call_4188', 'index': 0, 'type': 'tool_call_chunk'}])], tool_call_id='call_4188')],\n",
    "  'messages': [AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_4188', 'function': {'arguments': '{\"word\":\"eudca\"}', 'name': 'get_word_length'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls'}, id='run-6cc153ac-50f7-468e-871a-bb81fd15b1f7', tool_calls=[{'name': 'get_word_length', 'args': {'word': 'eudca'}, 'id': 'call_4188', 'type': 'tool_call'}], usage_metadata={'input_tokens': 966, 'output_tokens': 86, 'total_tokens': 1052}, tool_call_chunks=[{'name': 'get_word_length', 'args': '{\"word\":\"eudca\"}', 'id': 'call_4188', 'index': 0, 'type': 'tool_call_chunk'}])]},\n",
    " {'steps': [AgentStep(action=ToolAgentAction(tool='get_word_length', tool_input={'word': 'eudca'}, log=\"\\nInvoking: `get_word_length` with `{'word': 'eudca'}`\\n\\n\\n\", message_log=[AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_4188', 'function': {'arguments': '{\"word\":\"eudca\"}', 'name': 'get_word_length'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls'}, id='run-6cc153ac-50f7-468e-871a-bb81fd15b1f7', tool_calls=[{'name': 'get_word_length', 'args': {'word': 'eudca'}, 'id': 'call_4188', 'type': 'tool_call'}], usage_metadata={'input_tokens': 966, 'output_tokens': 86, 'total_tokens': 1052}, tool_call_chunks=[{'name': 'get_word_length', 'args': '{\"word\":\"eudca\"}', 'id': 'call_4188', 'index': 0, 'type': 'tool_call_chunk'}])], tool_call_id='call_4188'), observation=5)],\n",
    "  'messages': [FunctionMessage(content='5', additional_kwargs={}, response_metadata={}, name='get_word_length')]},\n",
    " {'output': '5',\n",
    "  'messages': [AIMessage(content='5', additional_kwargs={}, response_metadata={})]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Here\\'s how to solve this:\\n\\n* **Focus on the phrase:**  The question asks about the letters in the phrase \"letters in the word educa\".\\n* **Count carefully:** Count each letter in that phrase.\\n\\nLet me know if you\\'d like me to do the counting for you! \\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 67, 'prompt_tokens': 16, 'total_tokens': 83, 'completion_time': 0.121818182, 'prompt_time': 0.00024042, 'queue_time': 0.042495864, 'total_time': 0.122058602}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-ed352c53-84e7-48d6-9576-0acd99befd1f-0', usage_metadata={'input_tokens': 16, 'output_tokens': 67, 'total_tokens': 83})"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"How many letters in the word educa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "\n",
    "MEMORY_KEY = \"chat_history\"\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are very powerful assistant, but bad at calculating lengths of words.\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=MEMORY_KEY),\n",
    "        (\"user\", \"{input}\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "\n",
    "chat_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = (\n",
    "    {\n",
    "        \"input\": lambda x: x[\"input\"],\n",
    "        \"agent_scratchpad\": lambda x: format_to_openai_tool_messages(\n",
    "            x[\"intermediate_steps\"]\n",
    "        ),\n",
    "        \"chat_history\": lambda x: x[\"chat_history\"],\n",
    "    }\n",
    "    | prompt\n",
    "    | llm_with_tools\n",
    "    | OpenAIToolsAgentOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in StdOutCallbackHandler.on_chain_start callback: AttributeError(\"'NoneType' object has no attribute 'get'\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `get_word_length` with `{'word': 'educa'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m5\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in StdOutCallbackHandler.on_chain_start callback: AttributeError(\"'NoneType' object has no attribute 'get'\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m5\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mYes. \n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'is that a real word?',\n",
       " 'chat_history': [HumanMessage(content='how many letters in the word educa?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='5', additional_kwargs={}, response_metadata={})],\n",
       " 'output': 'Yes. \\n'}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input1 = \"how many letters in the word educa?\"\n",
    "result = agent_executor.invoke({\"input\": input1, \"chat_history\": chat_history})\n",
    "chat_history.extend(\n",
    "    [\n",
    "        HumanMessage(content=input1),\n",
    "        AIMessage(content=result[\"output\"]),\n",
    "    ]\n",
    ")\n",
    "agent_executor.invoke({\"input\": \"is that a real word?\", \"chat_history\": chat_history})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
